{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone \n",
    "Goal is to make the files with 24 hour columns horizontally into a more vertical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From sponsor\n",
    "- Data is the load data we receive with solar included \n",
    "- DataLessSolar is the data we receive without the solar \n",
    "- SolarSanitized contains formulas that subtract Data less solar from data and results in solar contribution.  \n",
    "- Data Simple is the “Data” information without decimals to make it simplified.\n",
    "\n",
    "### We will not be using Data Simple - no reason to remove decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# File path\n",
    "file_path = 'LoadBFY2025.xlsx'\n",
    "\n",
    "# Load specific sheets into separate DataFrames\n",
    "basic_data = pd.read_excel(file_path, sheet_name='Data')\n",
    "basic_data_no_solar = pd.read_excel(file_path, sheet_name='DataLessSolar')\n",
    "solar_data = pd.read_excel(file_path, sheet_name='Solarsanitized') \n",
    "\n",
    "# Print the first few rows for verification\n",
    "print(\"Basic Load Data:\")\n",
    "print(basic_data.head(2))\n",
    "\n",
    "print(\"\\nHBasic Load Data w/out Solar:\")\n",
    "print(basic_data_no_solar.head(2))\n",
    "\n",
    "print(\"\\nSolar only Data:\")\n",
    "print(solar_data.head(2))\n",
    "\n",
    "# Store all sheets in a dictionary for easy reference and analysis later\n",
    "all_load_sheets = {\n",
    "    \"BasicLoad\": basic_data,\n",
    "    \"BasicLoadNoSolar\": basic_data_no_solar,\n",
    "    \"SolarData\": solar_data,\n",
    "}\n",
    "\n",
    "# Print the keys of the dictionary to verify\n",
    "print(\"Loaded Data Sheets:\")\n",
    "print(all_load_sheets.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data for BasicLoad:\n",
      "          Dt  Hour  BasicLoad\n",
      "0 1989-01-01     1      142.0\n",
      "1 1989-01-01     2      124.0\n",
      "2 1989-01-01     3      117.0\n",
      "3 1989-01-01     4      112.0\n",
      "4 1989-01-01     5      112.0\n",
      "5 1989-01-01     6      114.0\n",
      "6 1989-01-01     7      117.0\n",
      "7 1989-01-01     8      127.0\n",
      "8 1989-01-01     9      140.0\n",
      "9 1989-01-01    10      161.0\n",
      "\n",
      "Transformed Data for BasicLoadNoSolar:\n",
      "          Dt  Hour  BasicLoadNoSolar\n",
      "0 1989-01-01     1             142.0\n",
      "1 1989-01-01     2             124.0\n",
      "2 1989-01-01     3             117.0\n",
      "3 1989-01-01     4             112.0\n",
      "4 1989-01-01     5             112.0\n",
      "5 1989-01-01     6             114.0\n",
      "6 1989-01-01     7             117.0\n",
      "7 1989-01-01     8             127.0\n",
      "8 1989-01-01     9             140.0\n",
      "9 1989-01-01    10             161.0\n",
      "\n",
      "Transformed Data for SolarData:\n",
      "          Dt  Hour  SolarData\n",
      "0 1989-01-01     1        0.0\n",
      "1 1989-01-01     2        0.0\n",
      "2 1989-01-01     3        0.0\n",
      "3 1989-01-01     4        0.0\n",
      "4 1989-01-01     5        0.0\n",
      "5 1989-01-01     6        0.0\n",
      "6 1989-01-01     7        0.0\n",
      "7 1989-01-01     8        0.0\n",
      "8 1989-01-01     9        0.0\n",
      "9 1989-01-01    10        0.0\n"
     ]
    }
   ],
   "source": [
    "# List of sheets that require transformation\n",
    "sheets_to_transform = ['BasicLoad', 'BasicLoadNoSolar', 'SolarData']\n",
    "\n",
    "# Dictionary to store transformed DataFrames\n",
    "transformed_load_sheets = {}\n",
    "\n",
    "# Transform the data for each specified sheet\n",
    "for sheet_name in sheets_to_transform:\n",
    "    # Access the sheet from the previously loaded dictionary\n",
    "    data = all_load_sheets[sheet_name]\n",
    "    \n",
    "    # Reshape the data from wide to long format\n",
    "    data_long = data.melt(\n",
    "        id_vars=['Dt'],  # Columns to keep as is\n",
    "        value_vars=[f'H{i}' for i in range(1, 25)],  # Columns to unpivot\n",
    "        var_name='Hour',  # Name of the new column for hours\n",
    "        value_name=sheet_name  # Name of the new column for the values\n",
    "    )\n",
    "    \n",
    "    # Convert the 'Hour' column from 'H1', 'H2', etc., to integers (1-24)\n",
    "    data_long['Hour'] = data_long['Hour'].str.extract('H(\\d+)').astype(int)\n",
    "    \n",
    "    # Sort the data by date (`Dt`) and hour (`Hour`)\n",
    "    data_long = data_long.sort_values(by=['Dt', 'Hour']).reset_index(drop=True)\n",
    "    \n",
    "    # Store the transformed DataFrame\n",
    "    transformed_load_sheets[sheet_name] = data_long\n",
    "\n",
    "    # Print a preview of the transformed data for verification\n",
    "    print(f\"\\nTransformed Data for {sheet_name}:\")\n",
    "    print(data_long.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dt  Hour  BasicLoad  BasicLoadNoSolar  SolarData\n",
      "0 2000-01-01     1      193.0             193.0        0.0\n",
      "1 2000-01-01     2      193.0             193.0        0.0\n",
      "2 2000-01-01     3      184.0             184.0        0.0\n",
      "3 2000-01-01     4      175.0             175.0        0.0\n",
      "4 2000-01-01     5      172.0             172.0        0.0\n"
     ]
    }
   ],
   "source": [
    "# Specify the start date for filtering\n",
    "start_date = \"2000-01-01\"\n",
    "\n",
    "# Filter and prepare all transformed data for merging\n",
    "for sheet_name in transformed_load_sheets:\n",
    "    # Filter rows where the date is >= January 1, 2000\n",
    "    transformed_load_sheets[sheet_name] = transformed_load_sheets[sheet_name][\n",
    "        transformed_load_sheets[sheet_name]['Dt'] >= start_date\n",
    "    ]\n",
    "\n",
    "# Start with the first sheet for merging\n",
    "merged_data = transformed_load_sheets['BasicLoad']\n",
    "\n",
    "# Merge all DataFrames on common columns: 'Dt' and 'Hour'\n",
    "for sheet_name in ['BasicLoadNoSolar', 'SolarData']:\n",
    "    merged_data = pd.merge(\n",
    "        merged_data,\n",
    "        transformed_load_sheets[sheet_name],\n",
    "        on=['Dt', 'Hour'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "# Drop unnecessary columns after merging\n",
    "columns_to_drop = ['CompID']  # Add any other irrelevant columns here if needed\n",
    "merged_data = merged_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Display the first few rows of the updated data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Save the output to a CSV file\n",
    "merged_data.to_csv('merged_load_data_verticalFormat_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar didn't start until later - below shows which date it first had a non-zero value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first non-zero value in SolarData occurs on: 2010-04-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Find the first row where the SolarData column is non-zero\n",
    "first_non_zero_row = merged_data[merged_data['SolarData'] != 0].iloc[0]\n",
    "\n",
    "# Extract the date corresponding to the first non-zero value\n",
    "first_non_zero_date = first_non_zero_row['Dt']\n",
    "\n",
    "# Display the result\n",
    "print(f\"The first non-zero value in SolarData occurs on: {first_non_zero_date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging temperature and loads for Sam to utilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Dt  Hour  BasicLoad  BasicLoadNoSolar  SolarData       Temp\n",
      "0  2000-01-01     1      193.0             193.0        0.0  58.871429\n",
      "1  2000-01-01     2      193.0             193.0        0.0  58.257143\n",
      "2  2000-01-01     3      184.0             184.0        0.0  58.071429\n",
      "3  2000-01-01     4      175.0             175.0        0.0  58.300000\n",
      "4  2000-01-01     5      172.0             172.0        0.0  58.371429\n"
     ]
    }
   ],
   "source": [
    "# Load the load data file\n",
    "load_data = pd.read_csv('merged_load_data_verticalFormat_cleaned.csv')\n",
    "\n",
    "# Load the weather data file\n",
    "weather_data = pd.read_csv('../weather_files/merged_weather_data_verticalFormat_cleaned.csv')       # make sure path correct after relocating to the 'weather_files' folder\n",
    "\n",
    "\n",
    "# Merge the datasets on 'Dt' and 'Hour' columns\n",
    "merged_data = pd.merge(load_data, weather_data[['Dt', 'Hour', 'Temp']], on=['Dt', 'Hour'], how='inner')\n",
    "\n",
    "# Display the first few rows of the merged dataset\n",
    "print(merged_data.head())\n",
    "\n",
    "# Save the merged dataset to a new file\n",
    "merged_data.to_csv('merged_load_weather_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
