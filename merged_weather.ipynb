{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone \n",
    "Goal is to make the files with 24 hour columns horizontally into a more vertical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# File path\n",
    "file_path = 'Weather_BFY25.xlsx'\n",
    "\n",
    "# Load specific sheets into separate DataFrames\n",
    "temp_data = pd.read_excel(file_path, sheet_name='Temp')\n",
    "humidity_data = pd.read_excel(file_path, sheet_name='Humidity')\n",
    "windspeed_data = pd.read_excel(file_path, sheet_name='WindSpeed')\n",
    "thi_data = pd.read_excel(file_path, sheet_name='THI')\n",
    "windchill_data = pd.read_excel(file_path, sheet_name='WindChill')\n",
    "\n",
    "# Load the other sheets (Rainfall and DailyWthr) - NOT CURRENTLY MODIFYING SINCE NOT IN HORIZONTAL FORMAT\n",
    "rainfall_data = pd.read_excel(file_path, sheet_name='Rainfall')\n",
    "daily_weather_data = pd.read_excel(file_path, sheet_name='DailyWthr')\n",
    "\n",
    "# Print the first few rows for verification\n",
    "print(\"Temp Data:\")\n",
    "print(temp_data.head(2))\n",
    "\n",
    "print(\"\\nHumidity Data:\")\n",
    "print(humidity_data.head(2))\n",
    "\n",
    "print(\"\\nWindspeed Data:\")\n",
    "print(windspeed_data.head(2))\n",
    "\n",
    "print(\"\\nTHI Data:\")\n",
    "print(thi_data.head(2))\n",
    "\n",
    "print(\"\\nWindchill Data:\")\n",
    "print(windchill_data.head(2))\n",
    "\n",
    "print(\"\\nRainfall Data:\")\n",
    "print(rainfall_data.head(2))\n",
    "\n",
    "print(\"\\nDaily Weather Data:\")\n",
    "print(daily_weather_data.head(2))\n",
    "\n",
    "# Store all sheets in a dictionary for easy reference and analysis later\n",
    "all_weather_sheets = {\n",
    "    \"Temp\": temp_data,\n",
    "    \"Humidity\": humidity_data,\n",
    "    \"Windspeed\": windspeed_data,\n",
    "    \"THI\": thi_data,\n",
    "    \"Windchill\": windchill_data,\n",
    "    \"Rainfall\": rainfall_data,\n",
    "    \"DailyWthr\": daily_weather_data\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data for Temp:\n",
      "  StationID ConceptID         Dt  Hour  Temp\n",
      "0       LAK       DBT 1989-01-01     1  65.0\n",
      "1       LAK       DBT 1989-01-01     2  66.0\n",
      "2       LAK       DBT 1989-01-01     3  65.0\n",
      "3       LAK       DBT 1989-01-01     4  64.0\n",
      "4       LAK       DBT 1989-01-01     5  64.0\n",
      "5       LAK       DBT 1989-01-01     6  64.0\n",
      "6       LAK       DBT 1989-01-01     7  65.0\n",
      "7       LAK       DBT 1989-01-01     8  65.0\n",
      "8       LAK       DBT 1989-01-01     9  67.0\n",
      "9       LAK       DBT 1989-01-01    10  75.0\n",
      "\n",
      "Transformed Data for Humidity:\n",
      "  StationID ConceptID         Dt  Hour  Humidity\n",
      "0       LAK       DBT 1999-01-01     1      89.0\n",
      "1       LAK       DBT 1999-01-01     2      92.0\n",
      "2       LAK       DBT 1999-01-01     3      95.5\n",
      "3       LAK       DBT 1999-01-01     4      97.5\n",
      "4       LAK       DBT 1999-01-01     5      98.5\n",
      "5       LAK       DBT 1999-01-01     6      98.5\n",
      "6       LAK       DBT 1999-01-01     7      98.5\n",
      "7       LAK       DBT 1999-01-01     8      98.5\n",
      "8       LAK       DBT 1999-01-01     9      96.5\n",
      "9       LAK       DBT 1999-01-01    10      80.0\n",
      "\n",
      "Transformed Data for Windspeed:\n",
      "  StationID ConceptID         Dt  Hour Windspeed\n",
      "0       LAK       DBT 1999-01-01     1         0\n",
      "1       LAK       DBT 1999-01-01     2         0\n",
      "2       LAK       DBT 1999-01-01     3         0\n",
      "3       LAK       DBT 1999-01-01     4         0\n",
      "4       LAK       DBT 1999-01-01     5         0\n",
      "5       LAK       DBT 1999-01-01     6         0\n",
      "6       LAK       DBT 1999-01-01     7         0\n",
      "7       LAK       DBT 1999-01-01     8         0\n",
      "8       LAK       DBT 1999-01-01     9         0\n",
      "9       LAK       DBT 1999-01-01    10      2.75\n",
      "\n",
      "Transformed Data for THI:\n",
      "  StationID ConceptID         Dt  Hour    THI\n",
      "0       LAK       DBT 1999-01-01     1  49.10\n",
      "1       LAK       DBT 1999-01-01     2  47.95\n",
      "2       LAK       DBT 1999-01-01     3  47.45\n",
      "3       LAK       DBT 1999-01-01     4  47.70\n",
      "4       LAK       DBT 1999-01-01     5  48.55\n",
      "5       LAK       DBT 1999-01-01     6  48.50\n",
      "6       LAK       DBT 1999-01-01     7  48.10\n",
      "7       LAK       DBT 1999-01-01     8  47.50\n",
      "8       LAK       DBT 1999-01-01     9  48.80\n",
      "9       LAK       DBT 1999-01-01    10  55.50\n",
      "\n",
      "Transformed Data for Windchill:\n",
      "  StationID ConceptID         Dt  Hour  Windchill\n",
      "0       LAK       DBT 1999-01-01     1      49.10\n",
      "1       LAK       DBT 1999-01-01     2      47.95\n",
      "2       LAK       DBT 1999-01-01     3      47.45\n",
      "3       LAK       DBT 1999-01-01     4      47.70\n",
      "4       LAK       DBT 1999-01-01     5      48.55\n",
      "5       LAK       DBT 1999-01-01     6      48.50\n",
      "6       LAK       DBT 1999-01-01     7      48.10\n",
      "7       LAK       DBT 1999-01-01     8      47.50\n",
      "8       LAK       DBT 1999-01-01     9      48.80\n",
      "9       LAK       DBT 1999-01-01    10      55.50\n"
     ]
    }
   ],
   "source": [
    "# List of sheets that require transformation\n",
    "sheets_to_transform = ['Temp', 'Humidity', 'Windspeed', 'THI', 'Windchill']\n",
    "\n",
    "# Dictionary to store transformed DataFrames\n",
    "transformed_weather_sheets = {}\n",
    "\n",
    "# Transform the data for each specified sheet\n",
    "for sheet_name in sheets_to_transform:\n",
    "    # Access the sheet from the previously loaded dictionary\n",
    "    data = all_weather_sheets[sheet_name]\n",
    "    \n",
    "    # Reshape the data from wide to long format\n",
    "    data_long = data.melt(\n",
    "        id_vars=['StationID', 'ConceptID', 'Dt'],  # Columns to keep as is\n",
    "        value_vars=[f'H{i}' for i in range(1, 25)],  # Columns to unpivot\n",
    "        var_name='Hour',  # Name of the new column for hours\n",
    "        value_name=sheet_name  # Name of the new column for the values\n",
    "    )\n",
    "    \n",
    "    # Convert the 'Hour' column from 'H1', 'H2', etc., to integers (1-24)\n",
    "    data_long['Hour'] = data_long['Hour'].str.extract('H(\\d+)').astype(int)\n",
    "    \n",
    "    # Sort the data by date (`Dt`) and hour (`Hour`)\n",
    "    data_long = data_long.sort_values(by=['Dt', 'Hour']).reset_index(drop=True)\n",
    "    \n",
    "    # Store the transformed DataFrame\n",
    "    transformed_weather_sheets[sheet_name] = data_long\n",
    "\n",
    "    # Print a preview of the transformed data for verification\n",
    "    print(f\"\\nTransformed Data for {sheet_name}:\")\n",
    "    print(data_long.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the changed variables together from 2000 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StationID ConceptID         Dt  Hour       Temp   Humidity Windspeed  \\\n",
      "0       LAK       DBT 2000-01-01     1  58.871429  88.142857  0.833333   \n",
      "1       LAK       DBT 2000-01-01     2  58.257143  88.142857      0.75   \n",
      "2       LAK       DBT 2000-01-01     3  58.071429  89.714286  0.833333   \n",
      "3       LAK       DBT 2000-01-01     4  58.300000  90.000000  0.833333   \n",
      "4       LAK       DBT 2000-01-01     5  58.371429  89.857143  0.666667   \n",
      "\n",
      "         THI  Windchill  \n",
      "0  59.650000  57.383333  \n",
      "1  59.216667  56.683333  \n",
      "2  58.950000  56.133333  \n",
      "3  59.266667  56.300000  \n",
      "4  59.266667  56.233333  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the start date for filtering\n",
    "start_date = \"2000-01-01\"\n",
    "\n",
    "# Filter and prepare all transformed data for merging\n",
    "for sheet_name in transformed_weather_sheets:\n",
    "    # Filter rows where the date is >= January 1, 2000\n",
    "    transformed_weather_sheets[sheet_name] = transformed_weather_sheets[sheet_name][\n",
    "        transformed_weather_sheets[sheet_name]['Dt'] >= start_date\n",
    "    ]\n",
    "\n",
    "# Merge all DataFrames on common columns: 'StationID', 'ConceptID', 'Dt', 'Hour'\n",
    "merged_data = transformed_weather_sheets['Temp']\n",
    "\n",
    "for sheet_name in ['Humidity', 'Windspeed', 'THI', 'Windchill']:\n",
    "    merged_data = pd.merge(\n",
    "        merged_data,\n",
    "        transformed_weather_sheets[sheet_name],\n",
    "        on=['StationID', 'ConceptID', 'Dt', 'Hour'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "# Remove 'StationID' and 'ConceptID' columns from the merged data\n",
    "merged_data = merged_data.drop(columns=['StationID', 'ConceptID'])\n",
    "\n",
    "# Display the first few rows of the updated data\n",
    "print(merged_data.head())\n",
    "\n",
    "# Save output\n",
    "merged_data.to_csv('merged_weather_data_verticalFormat_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rainfall and DailyWthr columns combining and cleaning up since only daily values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Dt  Rainfall  dbinRain      AvgDB  HDD55     HDD60     HDD65  \\\n",
      "0 2000-01-01   0.00500         1  65.441667    0.0  0.000000  0.000000   \n",
      "1 2000-01-02   0.00125         1  65.688690    0.0  0.000000  0.000000   \n",
      "2 2000-01-03   0.00125         1  65.799405    0.0  0.000000  0.000000   \n",
      "3 2000-01-04   0.00125         1  69.077381    0.0  0.000000  0.000000   \n",
      "4 2000-01-05   0.00000         0  58.308929    0.0  1.691071  6.691071   \n",
      "\n",
      "      CDD65  CDD70  CDD75  \n",
      "0  0.441667    0.0    0.0  \n",
      "1  0.688690    0.0    0.0  \n",
      "2  0.799405    0.0    0.0  \n",
      "3  4.077381    0.0    0.0  \n",
      "4  0.000000    0.0    0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'Rainfall' and 'DailyWthr' are loaded into the DataFrame from the previous script\n",
    "# Assuming 'rainfall_data' and 'daily_weather_data' are already loaded\n",
    "\n",
    "# Filter both DataFrames to start from Jan 1, 2000\n",
    "rainfall_data_filtered = rainfall_data[pd.to_datetime(rainfall_data['Dt']) >= '2000-01-01'].copy()\n",
    "daily_weather_data['Dt'] = pd.to_datetime(daily_weather_data[['Year', 'Month', 'Day']])\n",
    "daily_weather_data_filtered = daily_weather_data[daily_weather_data['Dt'] >= '2000-01-01'].copy()\n",
    "\n",
    "# Select relevant columns from DailyWthr\n",
    "daily_weather_data_filtered = daily_weather_data_filtered[['Dt', 'AvgDB', 'HDD55', 'HDD60', 'HDD65', 'CDD65', 'CDD70', 'CDD75']]\n",
    "\n",
    "# Merge the two DataFrames on the 'Dt' column\n",
    "merged_weather_data = pd.merge(\n",
    "    rainfall_data_filtered,\n",
    "    daily_weather_data_filtered,\n",
    "    on='Dt',\n",
    "    how='inner'  # Use 'inner' to ensure only dates that exist in both datasets are included\n",
    ")\n",
    "\n",
    "# Reset index for better readability\n",
    "merged_weather_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_weather_data.head())\n",
    "\n",
    "# Save the data\n",
    "merged_weather_data.to_csv(\"merged_weather_data_rain-daily.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
